2026-02-04 09:29:27 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 09:29:27 - __main__ - ERROR - [test_ambiguous_query_detection.py:174] - Ambiguous query detection test failed: module 'app.core.pipeline' has no attribute 'session_summary_logger'
Traceback (most recent call last):
  File "D:\PKDUY\AI-ML\Github projects\MY PROJECTS\chat-bot-with-memory\tests\test_ambiguous_query_detection.py", line 112, in test_ambiguous_query_detection
    session_summary_logger=pipeline_module.session_summary_logger
AttributeError: module 'app.core.pipeline' has no attribute 'session_summary_logger'. Did you mean: 'SessionSummaryLogger'?
2026-02-04 09:31:20 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 09:32:46 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 09:32:46 - __main__ - ERROR - [test_ambiguous_query_detection.py:175] - Ambiguous query detection test failed: ChatPipeline.__init__() got an unexpected keyword argument 'skip_llm_ambiguity_if_clear'
Traceback (most recent call last):
  File "D:\PKDUY\AI-ML\Github projects\MY PROJECTS\chat-bot-with-memory\tests\test_ambiguous_query_detection.py", line 104, in test_ambiguous_query_detection
    pipeline = ChatPipeline(
TypeError: ChatPipeline.__init__() got an unexpected keyword argument 'skip_llm_ambiguity_if_clear'
2026-02-04 09:33:24 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 09:34:07 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 09:34:07 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 09:34:08 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:34:08 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 09:34:08 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:34:08 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 09:34:08 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:34:08 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 09:34:09 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:34:09 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 09:34:09 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:34:09 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 09:34:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:34:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 09:34:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 09:34:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:34:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 09:34:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:34:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 09:34:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:34:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 09:34:13 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 09:34:14 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 09:34:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:34:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 09:34:15 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 8
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:324] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:34:15 - app.core.pipeline - INFO - [pipeline.py:339] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:34:19 - app.core.pipeline - INFO - [pipeline.py:355] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:34:19 - __main__ - ERROR - [test_ambiguous_query_detection.py:174] - Ambiguous query detection test failed: 'query_understanding'
Traceback (most recent call last):
  File "D:\PKDUY\AI-ML\Github projects\MY PROJECTS\chat-bot-with-memory\tests\test_ambiguous_query_detection.py", line 127, in test_ambiguous_query_detection
    is_ambiguous = result['query_understanding'].get('is_ambiguous', False)
KeyError: 'query_understanding'
2026-02-04 09:34:19 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 09:35:42 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 09:35:48 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 09:35:48 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 09:35:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:35:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 09:35:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:35:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 09:35:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:35:50 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 09:35:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 09:35:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:35:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 09:35:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:35:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 09:35:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:35:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 09:35:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 09:35:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:35:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 09:35:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:35:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 09:35:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:35:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 09:35:53 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 09:35:53 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 09:35:53 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:35:53 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 09:35:54 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 12
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:324] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:35:54 - app.core.pipeline - INFO - [pipeline.py:361] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:379] - [Pipeline] Generated LLM response
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 131
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:324] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:35:58 - app.core.pipeline - INFO - [pipeline.py:361] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:379] - [Pipeline] Generated LLM response
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 251
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:324] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:36:02 - app.core.pipeline - INFO - [pipeline.py:361] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:379] - [Pipeline] Generated LLM response
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 429
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:36:08 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:36:09 - app.core.pipeline - INFO - [pipeline.py:314] - [Pipeline] Generated concise final_augmented_context via LLM
2026-02-04 09:36:09 - app.core.pipeline - INFO - [pipeline.py:324] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:36:09 - app.core.pipeline - INFO - [pipeline.py:339] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:355] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 528
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:36:13 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:36:14 - app.core.pipeline - INFO - [pipeline.py:314] - [Pipeline] Generated concise final_augmented_context via LLM
2026-02-04 09:36:14 - app.core.pipeline - INFO - [pipeline.py:324] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:36:14 - app.core.pipeline - INFO - [pipeline.py:361] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:379] - [Pipeline] Generated LLM response
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 583
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:36:19 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:36:21 - app.core.pipeline - INFO - [pipeline.py:314] - [Pipeline] Generated concise final_augmented_context via LLM
2026-02-04 09:36:21 - app.core.pipeline - INFO - [pipeline.py:324] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:36:21 - app.core.pipeline - INFO - [pipeline.py:339] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:355] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 684
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:36:25 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:36:26 - app.core.pipeline - INFO - [pipeline.py:314] - [Pipeline] Generated concise final_augmented_context via LLM
2026-02-04 09:36:26 - app.core.pipeline - INFO - [pipeline.py:324] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:36:26 - app.core.pipeline - INFO - [pipeline.py:329] - [Pipeline] Query refined: How does This compare?
2026-02-04 09:36:26 - app.core.pipeline - INFO - [pipeline.py:339] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:355] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 785
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:36:30 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:36:32 - app.core.pipeline - INFO - [pipeline.py:314] - [Pipeline] Generated concise final_augmented_context via LLM
2026-02-04 09:36:32 - app.core.pipeline - INFO - [pipeline.py:324] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:36:32 - app.core.pipeline - INFO - [pipeline.py:339] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:355] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 838
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:36:35 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:36:37 - app.core.pipeline - INFO - [pipeline.py:314] - [Pipeline] Generated concise final_augmented_context via LLM
2026-02-04 09:36:37 - app.core.pipeline - INFO - [pipeline.py:324] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:36:37 - app.core.pipeline - INFO - [pipeline.py:329] - [Pipeline] Query refined: Is I'd the same?
2026-02-04 09:36:37 - app.core.pipeline - INFO - [pipeline.py:339] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:36:40 - app.core.pipeline - INFO - [pipeline.py:355] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:36:40 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 09:46:46 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 09:46:53 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 09:46:53 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 09:46:54 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:46:54 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 09:46:54 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:46:54 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 09:46:54 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 09:46:54 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:46:54 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 09:46:55 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:46:55 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 09:46:55 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:46:55 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 09:46:55 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:46:55 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 09:46:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 09:46:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:46:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 09:46:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:46:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 09:46:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:46:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 09:46:57 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 09:46:57 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 09:46:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:46:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 09:46:58 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 11
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:46:58 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 259
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:47:03 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 294
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:47:08 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 415
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:47:12 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 529
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:47:14 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 634
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:47:19 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 732
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:47:23 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 826
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:47:28 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 897
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:47:33 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:47:38 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:47:38 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 09:51:47 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 09:51:53 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 09:51:53 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 09:51:54 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:51:54 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 09:51:55 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:51:55 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 09:51:55 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:51:55 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 09:51:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:51:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 09:51:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:51:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 09:51:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:51:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 09:51:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 09:51:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:51:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 09:51:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:51:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 09:51:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:51:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 09:51:58 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 09:51:59 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 09:51:59 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:51:59 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 09:52:00 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 12
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:52:00 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 634
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:52:04 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 783
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:52:09 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1200
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:52:14 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1303
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:52:17 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1396
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:52:21 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1500
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:52:25 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1587
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:52:30 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1678
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:52:34 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:52:38 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:52:38 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 09:55:49 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 09:55:55 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 09:55:55 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 09:55:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:55:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 09:55:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:55:56 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 09:55:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:55:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 09:55:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:55:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 09:55:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:55:57 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 09:55:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:55:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 09:55:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 09:55:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:55:58 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 09:55:59 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:55:59 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 09:55:59 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:55:59 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 09:56:00 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 09:56:00 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 09:56:00 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 09:56:00 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 09:56:01 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 8
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:56:01 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 107
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:56:02 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 240
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:56:07 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 305
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:56:12 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 411
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:56:15 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 537
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:56:20 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 648
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:56:24 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 682
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:56:29 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 716
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 09:56:34 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 09:56:39 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 09:56:39 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 10:10:19 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 10:10:25 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 10:10:25 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 10:10:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:10:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:10:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:10:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:10:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:10:26 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 10:10:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:10:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:10:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 10:10:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:10:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:10:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:10:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 10:10:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 10:10:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:10:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:10:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:10:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:10:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:10:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 10:10:30 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 10:10:30 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 10:10:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:10:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 10:10:31 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 9
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:10:31 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 116
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:10:35 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 351
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:10:40 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 543
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:10:45 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 628
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:10:48 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 662
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:10:53 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 839
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:10:57 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 895
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:11:01 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 986
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:11:05 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:11:09 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:11:09 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 10:15:54 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 10:16:00 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 10:16:00 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 10:16:01 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:16:01 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:16:01 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:16:02 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:16:02 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:16:02 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:16:03 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:16:03 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 10:16:03 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:16:03 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:16:03 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:16:03 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 10:16:04 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 10:16:04 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:16:04 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:16:04 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:16:05 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:16:05 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:16:05 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 10:16:05 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 10:16:06 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 10:16:06 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:16:06 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 10:16:06 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 9
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:16:06 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 150
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:16:11 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 243
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:16:15 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 339
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:16:19 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 444
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:16:23 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 535
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:16:27 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:16:31 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:16:31 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 10:16:31 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 647
2026-02-04 10:16:31 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:16:31 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:16:31 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:16:31 - __main__ - ERROR - [test_ambiguous_query_detection.py:188] - Ambiguous query detection test failed: local variable 'unique_candidates' referenced before assignment
Traceback (most recent call last):
  File "D:\PKDUY\AI-ML\Github projects\MY PROJECTS\chat-bot-with-memory\tests\test_ambiguous_query_detection.py", line 164, in test_ambiguous_query_detection
    result = await pipeline.process_message(session_id, follow_up)
  File "D:\PKDUY\AI-ML\Github projects\MY PROJECTS\chat-bot-with-memory\app\core\pipeline.py", line 197, in process_message
    ambiguity_analysis = await self.ambiguity_detector.detect(user_query, messages)
  File "D:\PKDUY\AI-ML\Github projects\MY PROJECTS\chat-bot-with-memory\app\query_understanding\ambiguity.py", line 147, in detect
    heuristic_result = self._heuristic_check(query, context)
  File "D:\PKDUY\AI-ML\Github projects\MY PROJECTS\chat-bot-with-memory\app\query_understanding\ambiguity.py", line 88, in _heuristic_check
    if not context or len(unique_candidates) == 0:
UnboundLocalError: local variable 'unique_candidates' referenced before assignment
2026-02-04 10:16:31 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 10:17:07 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 10:17:14 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 10:17:14 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 10:17:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:17:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:17:15 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:17:15 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:17:15 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:17:15 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:17:15 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:17:15 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 10:17:15 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 10:17:16 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:17:16 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:17:16 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:17:16 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 10:17:16 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 10:17:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:17:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:17:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:17:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:17:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:17:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 10:17:18 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 10:17:18 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 10:17:19 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:17:19 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 10:17:19 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 9
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:17:19 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 98
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:17:20 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 226
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:17:25 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 323
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:17:30 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 432
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:17:35 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 521
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:17:39 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 583
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:17:43 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 695
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:17:47 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 808
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:17:51 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:17:56 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:17:56 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 10:20:19 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 10:20:25 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 10:20:25 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 10:20:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:20:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:20:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:20:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:20:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:20:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:20:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:20:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 10:20:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:20:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:20:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:20:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 10:20:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 10:20:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:20:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:20:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:20:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:20:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:20:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 10:20:30 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 10:20:30 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 10:20:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:20:30 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 10:20:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 10:20:31 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_summarization_session
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 18
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:20:31 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_summarization_session
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 119
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:20:35 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_summarization_session
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 158
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:20:39 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_summarization_session
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 220
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:20:42 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_summarization_session
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 320
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:20:43 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_summarization_session
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 432
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:20:47 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_summarization_session
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 540
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:20:51 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:20:55 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:20:55 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_summarization_session
2026-02-04 10:20:55 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 665
2026-02-04 10:20:55 - app.core.pipeline - INFO - [pipeline.py:147] - [Pipeline] Context exceeded (665 > 600), summarizing
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['open_questions']
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:20:59 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_summarization_session
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 187
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['open_questions']
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:21:03 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #10 for session test_summarization_session
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 244
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:21:06 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #11 for session test_summarization_session
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 300
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:21:10 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #12 for session test_summarization_session
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 342
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['open_questions']
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:21:13 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #13 for session test_summarization_session
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 454
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:21:17 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #14 for session test_summarization_session
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 492
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['open_questions']
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:21:20 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #15 for session test_summarization_session
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 551
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:21:23 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:21:26 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:21:26 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_summarization_session deleted
2026-02-04 10:28:38 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 10:28:48 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 10:28:48 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 10:28:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:28:49 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 10:28:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:28:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:28:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:28:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:28:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:28:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:28:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 10:28:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:28:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:28:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:28:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 10:28:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 10:28:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:28:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:28:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:28:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:28:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:28:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 10:28:52 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 10:28:53 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 10:28:53 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:28:53 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 10:28:54 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_summarization_session
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 21
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:28:54 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_summarization_session
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 73
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:28:58 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_summarization_session
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 139
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:01 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_summarization_session
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 184
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:05 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_summarization_session
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 306
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:09 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_summarization_session
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 347
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:13 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_summarization_session
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 391
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:16 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_summarization_session
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 454
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:20 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_summarization_session
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 515
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:23 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #10 for session test_summarization_session
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 558
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:27 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #11 for session test_summarization_session
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 602
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:30 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #12 for session test_summarization_session
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 643
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:33 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #13 for session test_summarization_session
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 683
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: []
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:37 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:40 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:40 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #14 for session test_summarization_session
2026-02-04 10:29:40 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 726
2026-02-04 10:29:40 - app.core.pipeline - INFO - [pipeline.py:147] - [Pipeline] Context exceeded (726 > 700), summarizing
2026-02-04 10:29:53 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:53 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:53 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:53 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:29:53 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:53 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 1.0)
2026-02-04 10:29:53 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:53 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['user_profile.prefs', 'key_facts']
2026-02-04 10:29:53 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:53 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #15 for session test_summarization_session
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 114
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:229] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['user_profile.prefs', 'key_facts']
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:29:57 - app.core.pipeline - INFO - [pipeline.py:280] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:296] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #16 for session test_summarization_session
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 229
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 1.0)
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['user_profile.prefs', 'key_facts', 'open_questions']
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:30:01 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #17 for session test_summarization_session
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 270
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 1.0)
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['user_profile.prefs', 'key_facts', 'open_questions']
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:30:04 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #18 for session test_summarization_session
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 314
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 1.0)
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['user_profile.prefs', 'key_facts']
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:30:08 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #19 for session test_summarization_session
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 356
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 1.0)
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['user_profile.prefs', 'key_facts']
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:30:11 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #20 for session test_summarization_session
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 398
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:185] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:188] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:196] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:212] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:225] - [Pipeline] Answerable: True (confidence: 1.0)
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:235] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:243] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:259] - [Pipeline] Memory fields used: ['user_profile.prefs', 'key_facts', 'open_questions']
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:265] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:30:15 - app.core.pipeline - INFO - [pipeline.py:302] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:30:18 - app.core.pipeline - INFO - [pipeline.py:320] - [Pipeline] Generated LLM response
2026-02-04 10:30:18 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_summarization_session deleted
2026-02-04 10:40:32 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 10:40:41 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 10:40:41 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 10:40:42 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:40:42 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:40:43 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:40:43 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:40:43 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:40:43 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:40:43 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:40:43 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 10:40:44 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:40:44 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:40:44 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:40:44 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 10:40:44 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 10:40:45 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:40:45 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:40:46 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:40:46 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 10:40:46 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:47:13 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 10:47:24 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 10:47:24 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 10:47:25 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:47:25 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:47:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:47:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:47:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:47:26 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:47:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:47:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 10:47:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:47:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:47:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:47:27 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 10:47:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 10:47:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:47:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:47:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:47:28 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:47:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:47:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 10:47:29 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 10:47:29 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 10:47:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:47:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 10:47:31 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 10
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:47:31 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:47:36 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:47:36 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 10:49:22 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 10:49:29 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 10:49:29 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 10:49:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:49:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:49:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:49:29 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:49:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:49:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:49:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:49:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 10:49:30 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:49:31 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:49:31 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:49:31 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 10:49:31 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 10:49:32 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:49:32 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:49:32 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:49:32 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:49:32 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:49:32 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 10:49:33 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 10:49:33 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 10:49:33 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:49:33 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 10:49:34 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 10
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:49:34 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 160
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:49:39 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 254
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:49:43 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 386
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does That compare?
2026-02-04 10:49:47 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 469
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Is I'd important?
2026-02-04 10:49:51 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 571
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:49:56 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 608
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does Feel compare to PyTorch?
2026-02-04 10:50:01 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 701
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: which of these - Could, Are - do you prefer?
2026-02-04 10:50:04 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 806
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: which of these - Could, Which, NLP - is faster?
2026-02-04 10:50:09 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #10 for session test_ambiguity_session
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 910
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:14 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #11 for session test_ambiguity_session
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 945
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Can I use the same approach - Feel -?
2026-02-04 10:50:18 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #12 for session test_ambiguity_session
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 979
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Can I apply similar principles - Feel -?
2026-02-04 10:50:23 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #13 for session test_ambiguity_session
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1043
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: What option should I choose - This or To?
2026-02-04 10:50:28 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #14 for session test_ambiguity_session
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1123
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: What option should I pick - I'd or Could?
2026-02-04 10:50:31 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #15 for session test_ambiguity_session
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1222
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: For my deep learning project, what library should I choose - I'd or Could?
2026-02-04 10:50:35 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:50:40 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:50:40 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #16 for session test_ambiguity_session
2026-02-04 10:50:40 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1252
2026-02-04 10:50:40 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:40 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:40 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:42 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 10:50:42 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:42 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:50:42 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:50:42 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:42 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:42 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:42 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:42 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #17 for session test_ambiguity_session
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1337
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:46 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #18 for session test_ambiguity_session
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1440
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:50 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #19 for session test_ambiguity_session
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1528
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:54 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #20 for session test_ambiguity_session
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1612
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: I'd is confusing.
2026-02-04 10:50:58 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #21 for session test_ambiguity_session
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1709
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:51:02 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #22 for session test_ambiguity_session
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1822
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:51:06 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #23 for session test_ambiguity_session
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1881
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:51:11 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:51:16 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:51:16 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #24 for session test_ambiguity_session
2026-02-04 10:51:16 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1912
2026-02-04 10:51:16 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:51:16 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:51:16 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Feel similar?
2026-02-04 10:51:17 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #25 for session test_ambiguity_session
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1999
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:51:18 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #26 for session test_ambiguity_session
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2094
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:51:22 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #27 for session test_ambiguity_session
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2159
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:51:27 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #28 for session test_ambiguity_session
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2223
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:51:32 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:51:37 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:51:37 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 10:53:56 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 10:54:02 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 10:54:02 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 10:54:03 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:54:03 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:54:03 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:54:03 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:54:04 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:54:04 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 10:54:04 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:54:04 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 10:54:04 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:54:04 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 10:54:05 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:54:05 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 10:54:05 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 10:54:05 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:54:05 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:54:06 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:54:06 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 10:54:06 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 10:54:06 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:54:06 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 10:54:07 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 10:54:07 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 10:54:07 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 10:54:07 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 10:54:08 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 10
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:08 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 820
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:13 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 914
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:17 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1095
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does That compare?
2026-02-04 10:54:22 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1192
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Is I'd important?
2026-02-04 10:54:26 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:54:30 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:54:30 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 10:54:30 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1304
2026-02-04 10:54:30 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:30 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:30 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:31 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:54:31 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:31 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:54:31 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:31 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:31 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:31 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:31 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1372
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does That compare to PyTorch?
2026-02-04 10:54:36 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1480
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: which of these - Could, Are, NLP - do you prefer?
2026-02-04 10:54:40 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1577
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: which of these - Could, Are, Should - is faster?
2026-02-04 10:54:45 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #10 for session test_ambiguity_session
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1690
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:49 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #11 for session test_ambiguity_session
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1756
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Can I use the same approach - This -?
2026-02-04 10:54:54 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #12 for session test_ambiguity_session
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1822
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Can I apply similar principles - This -?
2026-02-04 10:54:59 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #13 for session test_ambiguity_session
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1855
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: What option should I choose - Feel?
2026-02-04 10:55:04 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #14 for session test_ambiguity_session
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1934
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: What method should I pick - I'd or Could?
2026-02-04 10:55:07 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #15 for session test_ambiguity_session
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2025
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: For my deep learning project, what library should I choose - I'd or Could?
2026-02-04 10:55:11 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:55:16 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:55:16 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #16 for session test_ambiguity_session
2026-02-04 10:55:16 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2055
2026-02-04 10:55:16 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:16 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:16 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:18 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 10:55:18 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:18 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:55:18 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:55:18 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:18 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:18 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:18 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:18 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #17 for session test_ambiguity_session
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2149
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:22 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #18 for session test_ambiguity_session
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2235
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:27 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #19 for session test_ambiguity_session
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2321
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:31 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #20 for session test_ambiguity_session
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2412
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: I'd is confusing.
2026-02-04 10:55:35 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #21 for session test_ambiguity_session
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2507
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:39 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:55:42 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #22 for session test_ambiguity_session
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2604
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:43 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #23 for session test_ambiguity_session
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2666
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:48 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:55:53 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:55:53 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #24 for session test_ambiguity_session
2026-02-04 10:55:53 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2697
2026-02-04 10:55:53 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:53 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:53 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Feel similar?
2026-02-04 10:55:54 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #25 for session test_ambiguity_session
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2783
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:55:58 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #26 for session test_ambiguity_session
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2871
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:56:01 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #27 for session test_ambiguity_session
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2906
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:56:06 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #28 for session test_ambiguity_session
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 3000
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 10:56:11 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 10:56:16 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 10:56:16 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 11:01:11 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 11:01:18 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 11:01:18 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 11:01:19 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:01:19 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 11:01:19 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:01:19 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 11:01:20 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:01:20 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 11:01:20 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:01:20 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 11:01:20 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:01:20 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 11:01:21 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:01:21 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 11:01:21 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 11:01:21 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:01:21 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 11:01:21 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 11:01:22 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:01:22 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 11:01:22 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:01:22 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 11:01:23 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 11:01:23 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 11:01:23 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:01:23 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 11:01:24 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 19
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:01:24 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 143
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:01:29 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 176
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does How perform?
2026-02-04 11:01:34 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 263
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:01:37 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 359
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:01:41 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 407
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does That compare for training speed?
2026-02-04 11:01:46 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 535
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: which of these - Which, Could, Are - do you prefer?
2026-02-04 11:01:51 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:01:55 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:01:55 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 11:01:55 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 593
2026-02-04 11:01:55 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:01:55 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:01:55 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: We need something I'd trains fast and has good ecosystem
2026-02-04 11:01:56 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 649
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:00 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #10 for session test_ambiguity_session
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 682
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: What option should I choose - What or Feel?
2026-02-04 11:02:05 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #11 for session test_ambiguity_session
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 757
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:09 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #12 for session test_ambiguity_session
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 826
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:14 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #13 for session test_ambiguity_session
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 930
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Can we use the same approach - Can -?
2026-02-04 11:02:18 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #14 for session test_ambiguity_session
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1052
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:23 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #15 for session test_ambiguity_session
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1161
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Can we apply similar principles - Can - to text data?
2026-02-04 11:02:27 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:02:32 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:02:32 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #16 for session test_ambiguity_session
2026-02-04 11:02:32 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1222
2026-02-04 11:02:32 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:32 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:32 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:34 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:02:34 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:34 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:02:34 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:02:34 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:34 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:34 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:34 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:34 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #17 for session test_ambiguity_session
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1318
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:38 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #18 for session test_ambiguity_session
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1423
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:42 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:02:46 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:02:46 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #19 for session test_ambiguity_session
2026-02-04 11:02:46 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1517
2026-02-04 11:02:46 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:46 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:46 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:47 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:02:47 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:47 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:02:47 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:02:47 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:47 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:47 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:47 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:47 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: which of these - Which, Could, Are - faster?
2026-02-04 11:02:47 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #20 for session test_ambiguity_session
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1614
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:51 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #21 for session test_ambiguity_session
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1713
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:56 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #22 for session test_ambiguity_session
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1813
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Show me how to implement I'd CNN
2026-02-04 11:02:59 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #23 for session test_ambiguity_session
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1867
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:03:02 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:03:08 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:03:08 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #24 for session test_ambiguity_session
2026-02-04 11:03:08 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1974
2026-02-04 11:03:08 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:03:08 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:03:08 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: This similar?
2026-02-04 11:03:10 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #25 for session test_ambiguity_session
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2059
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does I'd work?
2026-02-04 11:03:14 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #26 for session test_ambiguity_session
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2149
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:03:18 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #27 for session test_ambiguity_session
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2217
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:03:23 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #28 for session test_ambiguity_session
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2285
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:03:28 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:03:33 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:03:33 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 11:04:42 - app.llm.client - INFO - [client.py:62] - ✓ Gemini client initialized successfully
2026-02-04 11:04:48 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 11:04:48 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 11:04:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:04:49 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 11:04:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 11:04:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:04:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 11:04:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:04:49 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 11:04:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:04:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 11:04:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:04:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 11:04:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:04:50 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 11:04:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 11:04:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:04:51 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 11:04:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:04:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 11:04:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:04:52 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 11:04:53 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 11:04:53 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 11:04:53 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:04:53 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 11:04:54 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 19
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:04:54 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 168
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:04:59 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 229
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does Starting perform?
2026-02-04 11:05:04 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 324
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:07 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 421
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:12 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 457
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does TensorFlow compare for training speed?
2026-02-04 11:05:17 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 567
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: which of these - Which, Could, What - do you prefer?
2026-02-04 11:05:21 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:05:26 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:05:26 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 11:05:26 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 676
2026-02-04 11:05:26 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:26 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:26 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: We need something GPUs trains fast and has good ecosystem
2026-02-04 11:05:27 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 804
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:32 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #10 for session test_ambiguity_session
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 867
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: What framework should I choose - Regarding or Python?
2026-02-04 11:05:37 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #11 for session test_ambiguity_session
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 973
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:42 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #12 for session test_ambiguity_session
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1043
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:47 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #13 for session test_ambiguity_session
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1109
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Can we use the same approach - Can -?
2026-02-04 11:05:52 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #14 for session test_ambiguity_session
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1166
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:05:57 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #15 for session test_ambiguity_session
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1271
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Can we apply similar principles - Can - to text data?
2026-02-04 11:06:01 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:06:06 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:06:06 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #16 for session test_ambiguity_session
2026-02-04 11:06:06 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1331
2026-02-04 11:06:06 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:06 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:06 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:07 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:06:07 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:07 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:06:07 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:06:07 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:07 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:07 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:07 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:07 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #17 for session test_ambiguity_session
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1419
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:11 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #18 for session test_ambiguity_session
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1506
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:15 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:06:19 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:06:19 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #19 for session test_ambiguity_session
2026-02-04 11:06:19 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1606
2026-02-04 11:06:19 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:19 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:19 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:21 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:06:21 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:21 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:06:21 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:06:21 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:21 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:21 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:21 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:21 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: which of these - Which, Could, Are - faster?
2026-02-04 11:06:21 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #20 for session test_ambiguity_session
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1694
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:25 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #21 for session test_ambiguity_session
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1783
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:29 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #22 for session test_ambiguity_session
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1887
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Show me how to implement Natural CNN
2026-02-04 11:06:33 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #23 for session test_ambiguity_session
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1990
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:37 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:06:41 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:06:41 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #24 for session test_ambiguity_session
2026-02-04 11:06:41 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2072
2026-02-04 11:06:41 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:41 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:41 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: TensorFlow similar?
2026-02-04 11:06:43 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #25 for session test_ambiguity_session
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2160
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does Debugging work?
2026-02-04 11:06:48 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #26 for session test_ambiguity_session
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2272
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:52 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #27 for session test_ambiguity_session
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2316
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:06:57 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #28 for session test_ambiguity_session
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2366
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (rule-based entity replacement)
2026-02-04 11:07:02 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:07:07 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:07:07 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 11:18:20 - app.llm.client - WARNING - [client.py:64] - ⚠ Gemini initialization failed: google-generativeai package not installed.
Install with: pip install google-generativeai
2026-02-04 11:18:20 - app.llm.client - INFO - [client.py:65] - Falling back to Ollama...
2026-02-04 11:18:20 - app.llm.client - INFO - [client.py:81] - ✓ Ollama client initialized
2026-02-04 11:19:50 - app.llm.client - WARNING - [client.py:64] - ⚠ Gemini initialization failed: google-generativeai package not installed.
Install with: pip install google-generativeai
2026-02-04 11:19:50 - app.llm.client - INFO - [client.py:65] - Falling back to Ollama...
2026-02-04 11:19:50 - app.llm.client - INFO - [client.py:81] - ✓ Ollama client initialized
2026-02-04 11:19:51 - httpx - INFO - [_client.py:1740] - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 500 Internal Server Error"
2026-02-04 11:19:51 - app.llm.client - WARNING - [client.py:126] - ⚠ ollama generation failed: Server error '500 Internal Server Error' for url 'http://localhost:11434/api/chat'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500
2026-02-04 11:19:51 - httpx - INFO - [_client.py:1740] - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 500 Internal Server Error"
2026-02-04 11:19:51 - app.llm.client - WARNING - [client.py:126] - ⚠ ollama generation failed: Server error '500 Internal Server Error' for url 'http://localhost:11434/api/chat'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500
2026-02-04 11:28:58 - app.llm.client - INFO - [client.py:85] - ✓ Ollama client initialized
2026-02-04 11:28:58 - app.llm.client - INFO - [client.py:101] - ✓ Lightweight Ollama client initialized (qwen2.5:1.5b)
2026-02-04 11:28:59 - httpx - INFO - [_client.py:1740] - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 404 Not Found"
2026-02-04 11:28:59 - app.llm.client - WARNING - [client.py:271] - ⚠ Lightweight model inference failed: Model 'qwen2.5:1.5b' not found in Ollama.
Please pull the model: ollama pull qwen2.5:1.5b
2026-02-04 11:28:59 - app.llm.client - INFO - [client.py:272] - Falling back to ollama...
2026-02-04 11:28:59 - httpx - INFO - [_client.py:1740] - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 500 Internal Server Error"
2026-02-04 11:28:59 - app.llm.client - WARNING - [client.py:141] - ⚠ ollama generation failed: Server error '500 Internal Server Error' for url 'http://localhost:11434/api/chat'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500
2026-02-04 11:36:04 - app.llm.client - INFO - [client.py:66] - ✓ Gemini client initialized successfully
2026-02-04 11:36:04 - app.llm.client - INFO - [client.py:101] - ✓ Lightweight Ollama client initialized (qwen2.5:1.5b)
2026-02-04 11:38:06 - app.llm.client - INFO - [client.py:85] - ✓ Ollama client initialized
2026-02-04 11:38:06 - app.llm.client - INFO - [client.py:101] - ✓ Lightweight Ollama client initialized (qwen2.5:1.5b)
2026-02-04 11:38:12 - httpx - INFO - [_client.py:1740] - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
2026-02-04 11:38:43 - app.llm.client - INFO - [client.py:66] - ✓ Gemini client initialized successfully
2026-02-04 11:38:43 - app.llm.client - INFO - [client.py:101] - ✓ Lightweight Ollama client initialized (qwen2.5:1.5b)
2026-02-04 11:39:11 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 11:39:11 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 11:39:11 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:39:11 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 11:39:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:39:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 11:39:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:39:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 11:39:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:39:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 11:39:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:39:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 11:39:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:39:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 11:39:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 11:39:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:39:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 11:39:15 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:39:15 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 11:39:16 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:39:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 11:39:17 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 11:39:18 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 11:39:18 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:39:19 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 11:39:19 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session test_ambiguity_session
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 19
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:39:19 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session test_ambiguity_session
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 147
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:39:24 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session test_ambiguity_session
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 225
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:39:28 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:39:29 - httpx - INFO - [_client.py:1729] - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
2026-02-04 11:39:29 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How do they perform?
2026-02-04 11:39:29 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #4 for session test_ambiguity_session
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 328
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:39:33 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #5 for session test_ambiguity_session
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 416
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:39:37 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #6 for session test_ambiguity_session
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 477
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:39:42 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:39:43 - httpx - INFO - [_client.py:1729] - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
2026-02-04 11:39:43 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Which has better training speed: PyTorch or TensorFlow?
2026-02-04 11:39:43 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #7 for session test_ambiguity_session
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 587
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:39:47 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:39:50 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:39:50 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #8 for session test_ambiguity_session
2026-02-04 11:39:50 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 679
2026-02-04 11:39:50 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:39:50 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:39:50 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:39:52 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:39:52 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:39:52 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:39:52 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:39:52 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:39:52 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:39:52 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:39:52 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:39:52 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:39:52 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #9 for session test_ambiguity_session
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 781
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:39:55 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #10 for session test_ambiguity_session
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 844
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:00 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #11 for session test_ambiguity_session
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 949
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:05 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #12 for session test_ambiguity_session
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 987
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:10 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #13 for session test_ambiguity_session
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1054
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:15 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #14 for session test_ambiguity_session
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1100
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:20 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #15 for session test_ambiguity_session
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1217
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:24 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:40:29 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:40:29 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #16 for session test_ambiguity_session
2026-02-04 11:40:29 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1278
2026-02-04 11:40:29 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:29 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:29 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:30 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:40:30 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:30 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:40:30 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:40:30 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:30 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:30 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:30 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:30 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #17 for session test_ambiguity_session
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1328
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:34 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #18 for session test_ambiguity_session
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1419
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:38 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:40:42 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:40:42 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #19 for session test_ambiguity_session
2026-02-04 11:40:42 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1513
2026-02-04 11:40:42 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:42 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:42 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:43 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:40:43 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:43 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:40:43 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:40:43 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:43 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:43 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:43 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:43 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #20 for session test_ambiguity_session
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1595
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:48 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #21 for session test_ambiguity_session
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1690
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:51 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #22 for session test_ambiguity_session
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1785
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:55 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:56 - httpx - INFO - [_client.py:1729] - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
2026-02-04 11:40:56 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Show me how to implement this CNN.
2026-02-04 11:40:56 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #23 for session test_ambiguity_session
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1879
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:40:59 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:41:04 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:41:04 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #24 for session test_ambiguity_session
2026-02-04 11:41:04 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 1995
2026-02-04 11:41:04 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:41:04 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:41:04 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:41:05 - app.core.pipeline - INFO - [pipeline.py:217] - [Pipeline] Ambiguity: True (LLM used, confidence: 0.7)
2026-02-04 11:41:05 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:41:05 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:41:05 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:41:05 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:41:05 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:41:05 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:41:05 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:41:05 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:41:06 - httpx - INFO - [_client.py:1729] - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
2026-02-04 11:41:06 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: Is similar?
2026-02-04 11:41:06 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #25 for session test_ambiguity_session
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2088
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:41:10 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:41:11 - httpx - INFO - [_client.py:1729] - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
2026-02-04 11:41:11 - app.core.pipeline - INFO - [pipeline.py:277] - [Pipeline] Query refined: How does it work?
2026-02-04 11:41:11 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #26 for session test_ambiguity_session
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2187
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:41:15 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #27 for session test_ambiguity_session
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2325
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:41:20 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #28 for session test_ambiguity_session
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 2391
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:41:25 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:41:30 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 11:41:30 - scripts.session_manager - INFO - [session_manager.py:144] - Session test_ambiguity_session deleted
2026-02-04 11:50:40 - app.llm.client - INFO - [client.py:66] - ✓ Gemini client initialized successfully
2026-02-04 11:50:40 - app.llm.client - INFO - [client.py:101] - ✓ Lightweight Ollama client initialized (qwen2.5:1.5b)
2026-02-04 11:51:11 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 11:51:11 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 11:51:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:51:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 11:51:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:51:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 11:51:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:51:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 11:51:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:51:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 11:51:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:51:13 - huggingface_hub.utils._http - WARNING - [_http.py:779] - Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
2026-02-04 11:51:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 11:51:13 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:51:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 11:51:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 11:51:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:51:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 11:51:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:51:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 11:51:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:51:17 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 11:51:17 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 11:51:18 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 11:51:18 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 11:51:19 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 11:51:19 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 11:52:14 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session default_session
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 12
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 11:52:15 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 11:52:21 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 16:29:33 - app.llm.client - INFO - [client.py:66] - ✓ Gemini client initialized successfully
2026-02-04 16:29:33 - app.llm.client - INFO - [client.py:101] - ✓ Lightweight Ollama client initialized (qwen2.5:1.5b)
2026-02-04 16:30:09 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - Use pytorch device_name: cpu
2026-02-04 16:30:09 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-02-04 16:30:09 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 16:30:09 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 16:30:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 16:30:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 16:30:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config_sentence_transformers.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 16:30:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config_sentence_transformers.json "HTTP/1.1 200 OK"
2026-02-04 16:30:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/README.md "HTTP/1.1 307 Temporary Redirect"
2026-02-04 16:30:10 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/README.md "HTTP/1.1 200 OK"
2026-02-04 16:30:11 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/modules.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 16:30:11 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json "HTTP/1.1 200 OK"
2026-02-04 16:30:11 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 16:30:11 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json "HTTP/1.1 200 OK"
2026-02-04 16:30:11 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json "HTTP/1.1 404 Not Found"
2026-02-04 16:30:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 16:30:12 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 16:30:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 16:30:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json "HTTP/1.1 200 OK"
2026-02-04 16:30:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 16:30:14 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json "HTTP/1.1 200 OK"
2026-02-04 16:30:15 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false "HTTP/1.1 404 Not Found"
2026-02-04 16:30:15 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false "HTTP/1.1 200 OK"
2026-02-04 16:30:16 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json "HTTP/1.1 307 Temporary Redirect"
2026-02-04 16:30:16 - httpx - INFO - [_client.py:1013] - HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json "HTTP/1.1 200 OK"
2026-02-04 16:30:16 - httpx - INFO - [_client.py:1013] - HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 "HTTP/1.1 200 OK"
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #1 for session default_session
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 17
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: False (heuristic only, confidence: 0.95)
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: True (confidence: 0.9)
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 16:31:33 - app.core.pipeline - INFO - [pipeline.py:309] - [Pipeline] Step 6: Generating LLM response (answerable)
2026-02-04 16:31:42 - app.core.pipeline - INFO - [pipeline.py:327] - [Pipeline] Generated LLM response
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #2 for session default_session
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 746
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 16:31:51 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 16:31:55 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:126] - [Pipeline] Processing message #3 for session default_session
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:143] - [Pipeline] Token count: 844
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:192] - [Pipeline] === QUERY UNDERSTANDING PIPELINE ===
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:195] - [Pipeline] Step 1: Spelling check (rule-based)
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:203] - [Pipeline] Step 2: Ambiguity check (rule-first, LLM fallback)
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:219] - [Pipeline] Ambiguity: True (heuristic only, confidence: 0.85)
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:224] - [Pipeline] Step 3: Answerability check (similarity-based, NO LLM)
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:232] - [Pipeline] Answerable: False (confidence: 0.0)
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:236] - [Pipeline] Query not answerable - will return clarifying questions
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:242] - [Pipeline] Step 4: Context retrieval (selective)
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:250] - [Pipeline] Expanding context to 3 turns (pronoun/contrast detected)
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:257] - [Pipeline] Pronouns detected - including open_questions
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:266] - [Pipeline] Memory fields used: []
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:272] - [Pipeline] Step 5: Query refinement (LLM-assisted pronouns replacement)
2026-02-04 16:32:38 - app.core.pipeline - INFO - [pipeline.py:287] - [Pipeline] Step 6: Generating clarifying questions (not answerable)
2026-02-04 16:32:41 - app.core.pipeline - INFO - [pipeline.py:303] - [Pipeline] Generated clarifying questions (LLM call made)
